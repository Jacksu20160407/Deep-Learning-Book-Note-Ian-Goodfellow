# Deep Learning 5 chapter-Machine Learning

概念：

- 范化（generalization）：在先前未观测到的新输入上表现良好的能力。
- 权重（weight）：决定每一个特征对预测输出的影响。
- 偏置（bias）：模型的截距项。
- 模型容量（capacity）：模型能够拟合各种函数的能力。
- 过拟合（overfitting）：训练误差和测试误差之间的差距太大。
- 欠拟合（underfitting）：模型不能在训练集上获得足够低的误差。
- 超参数：对算法行为控制的参数
- 交叉验证：
- 全面调查：对研究对象的每一个个体都进行调查，观测，缺点是浪费大量人力物力财力
- 抽样调查：观测的只是总体的一小部分。优点是节省资金，时间，因为抽样调查只是调查总体的一部分，所以缺点是存在抽样误差。


取得样本的过程叫做抽样。抽样存在两重性：（1）样本特征在某种程度上反映 总体特征，（2）样本又不能完全精确的反映总体特征。要想让样本最大限度的反映总体特征就必须从两方面努力：（1）抽样方式（2）统计推断，即如何利用样本对总体的特征作出科学的推断。

如何保证*n*维随机向量的每次取样得到的样本对总体X最具有代表性呢？对于无限总体，应保证两点：（1）*n*个随机变量与总体X具有相同的概率分布，既保证每个个体有等同的机会被抽中（等可能性）。（2）随机变量之间是相互独立的。

训练机器学习模型，使得模型在训练集上的训练误差降低。这是一个模型优化问题。但是我们需要的是泛化误差降低，也就是在测试集上的性能来评估模型的泛化误差。

问题是我们只能观测到训练数据集，如何能保证在训练集上误差很低的模型在测试集上的泛化误差也很低呢？如果训练集和测试集完全没有关系，的确不能保证，但是我们通常假设训练集和测试集都采样自相同的数据分布，数据集中的每一个样本都是相互独立的，训练集和测试集是同分布的。我们将这个潜在的分布称为数据生成分布（data generating distribution），用p_data表示。假设有概率分布p(x, y)，我们从中重复采样得到训练和测试集，理想状态下，对于某个模型，我们能观察到的训练误差和测试误差之间的直接关系是，随机模型训练误差的期望和该模型测试误差的期望是一样的，这是因为这两个期望的计算都使用了相同的数据生成过程。实际中测试误差期望会大于或者等于训练误差期望。

因此我们可以通过以下方法提高算法性能：

  1. 降低模型训练误差
  2. 缩小训练误差和测试误差之间的差距

通过调整模型容量，可以控制模型是否偏向于过拟合或者欠拟合。容量低的模型一般很难拟合训练集，容量高的模型可能会记住不适用于测试集的训练集性质，从而产生过拟合。

如何控制算法容量？？一种方法是假设空间，即学习算法可以选择为解决方案的函数集（？？？）。

当机器学习算法的容量适合于所执行任务的复杂度和所提供训练数据的数量时（如何衡量这个‘适合’），算法的效果通常最佳。

以线性回归模型为例，假设训练数据是符合二次函数分布的数据集，我们分别使用一次函数，二次函数，九次函数去拟合数据集。显而易见，一次函数无法拟合该训练集，二次函数和九次函数都可以拟合该训练集。但是九次函数能够拟合无限多个刚好穿过训练样本点的函数。但是我们无法从这无限多个拟合函数中选出一个范化良好的函数。

这个例子同时也说明可以通过改变输入特征的数目和这些特征对应的参数来改变模型容量。还有其他方法可以改变模型容量（？？什么方法）。选择不同的模型决定了学习算法可以从哪些函数族中选择函数，这是模型的表示容量，实际中，学习算法不会找到最优的算法，只会找到最大降低训练误差的函数，这意味着算法的有效容量可能小于模型族的表示容量。

那么如何量化模型容量呢？可以通过统计学习理论中的VC维度方法。

> *不存在一种机器学习算法总是比其他的要好，这就表明机器学习研究的目不是找到一个通用的学习算法或者绝对好的学习算法，而是我们必须在特定任务上设计性能良好的学习算法。我们根据特定任务设计学习算法的偏好，当这些偏好与我们要解决的问题相一致时，就达到了最好的性能。*

  上个例子中，我们是通过**增减函数数量**的方法来增减模型容量。另外我们还可以通过**改变使用函数的种类**来控制算法的性能。例如加入权重衰减项来改变模型能够拟合的函数形状。更一般的情况是，我们给代价函数增加一个被称为正则化项的惩罚权重，对模型进行正则化，筛选出我们更加偏好的函数。正则化是指修改学习算法，使其降低泛化误差而非训练误差。

**超参数**一般无法通过学习得到，例如控制模型容量的超参数有，如果学习得到，那么这些超参数总是趋向于最大化模型容量，导致过拟合。为解决这个问题，一般设置验证集样本。验证集样本是来自于训练集的子集，两者没有交集。训练集用于学习模型参数，验证集用于估计训练中和训练后模型泛化误差以及衡量超参数的性能。

**交叉验证**指的是将数据集分成***k***互斥的子集，进行***k***次训练和测试，第***i***次训练测试时，第***i***个子集用于测试，其他数据用于训练。缺点是不存在平均误差方差的无偏估计（？？）

